{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc78340",
   "metadata": {},
   "source": [
    "# Chapter 2:  Probability Distribution (Summary)\n",
    "    \n",
    "<hr style=\"height:2px;\">   \n",
    "<h3>Density estimation</h3>\n",
    "\n",
    "It's unsupervised learninig aims to estimate a density given data from that distribution.<br>\n",
    "Given N observations $(i.i.d)$ from $P(X)$, try to model the probability distribution $P(X)$.\n",
    "<ul>\n",
    "  <li> <b>Parametric density estimation</b> : \n",
    "      <ul>\n",
    "          <li> Assumes that $P(X)$ from a known distribution goverened by some parameters w.\n",
    "          <li> Try to estimate these parameters w using frequentist or bayesian:\n",
    "              <ul>\n",
    "                  <li> <b> Frequentist</b> : Choose w that maximize or minimize some criterion(e.g. likelihood)\n",
    "                  <li> <b> Bayesian</b> : Introduce prior distributions over w, then use Bayes' theorem to esstimate the corresponding posterior given the observed data. \n",
    "              </ul>\n",
    "          <li>Examples: Conjugate prior approach, Mixture models\n",
    "      </ul><br>\n",
    "  <li> <b>Non-parametric density estimation</b>\n",
    "      <ul>\n",
    "          <li> Assume that the data has a probability density function but not of a specific known form\n",
    "          <li> Let data speak for themselves\n",
    "          <li> Examples: Histogram, Kernel-baased, \n",
    "      </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f64f5",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "<h3>Binary variables</h3>\n",
    "<br>\n",
    "<li> $X \\in \\{0, 1\\}$\n",
    "<li> $P(X=1)=\\mu$ and $P(X=0)= 1 - \\mu$ \n",
    "<li>Examples:\n",
    "    <ul>\n",
    "        <h4>1) Binomial distribution:</h4>\n",
    "        <ul>\n",
    "            <li> $m$ successive trails out of $N$, each with two possible outcomes.\n",
    "            <li> $\\text{Bin}(m|N, \\mu) = {N\\choose m}\\mu^m(1 - \\mu)^{N - m}$\n",
    "            <li> $\\text{Mean} = N\\mu$\n",
    "            <li> $\\sigma^2 = N\\mu(1 - \\mu)$\n",
    "            <li> It's conjugate prior is <b>Beta</b>\n",
    "        </ul>\n",
    "        <h4>2) Bernoulli distribution:</h4>\n",
    "        <ul>\n",
    "            <li> A special case of Binomial distribution, where $m = 1$:\n",
    "            <li> $\\text{Bern}(x|\\mu) = \\mu^x(1 - \\mu)^{1 - x}$\n",
    "            <li> $\\text{Mean} = \\mu$\n",
    "            <li> $\\sigma^2 = \\mu(1 - \\mu)$\n",
    "        </ul>\n",
    "    <h4>3) Beta distribution:</h4>\n",
    "    <ul>\n",
    "        <li> A continuous probability distribution defined on $[0,1]$\n",
    "        <li> $\\text{Beta}(\\mu|a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a) \\Gamma(b)} \\mu^{a-1}(1 - \\mu)^{b-1}$   \n",
    "        <li> Suitable for modeling r.v behaviour of percentages and proportions.\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1e022",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "<h3>Multinomial variables</h3><br>\n",
    "    $$\\quad\\text{Mult}(M|\\mu,N) = {N\\choose m{1} m{2}..m_{k}}\\prod_{k=1}^K \\mu_{k}^{m_{k}}, \\;\\;m_{k} = \\sum_{n} X_{nk}$$<br><br>\n",
    "<li> The d-dimensional Binomial.\n",
    "<li> $X$ is defined by a k-dimensional vector $X = \\{x_{1},..,x_{k}\\}$\n",
    "<li> Only $x_{k} = 1$ and all other x are zeros\n",
    "<li> The Binomial is a special case where $X \\in \\{x_{0}, x_{1}\\}$ and one of $x_{0}$ or $x_{1}$ is one with $\\mu$.\n",
    "<li> It's conjugate is Dirichlet distribution:\n",
    "    <ul>\n",
    "        <p>$$\\text{Dir}(\\mu|\\alpha) = \\frac{\\Gamma(\\alpha_{0})}{\\Gamma(\\alpha_{1})...\\Gamma(\\alpha_{k})}\\prod_{k=1}^K \\mu_{k}^{\\alpha_{k}-1} ,\\;\\;\\; \\alpha_{0} = \\sum^K \\alpha_k$$\n",
    "        <p> ,the k-dimensional Beta.\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abbdd0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "<h3>Gaussian Distributions</h3><br>\n",
    "<li> The sum of multiple random variables is gaussian.\n",
    "<li> The fractional dependence of gaussian on X through the mahalanobis distance: <br><br>\n",
    "    <p>$\\quad\\quad\\Delta^2 = (X - \\mu)^T\\Sigma^{-1}(X - \\mu)$<br><br>\n",
    "        <li> For $N(X|\\mu, \\Sigma)$, $\\;\\; X = {X_{a}\\choose X_{b}}$, $\\;\\;\\mu = {\\mu_{a}\\choose \\mu_{b}}$<b>:</b>\n",
    "            <ul>\n",
    "                <li> <b>1) The marginal distribution :</b><br><br>\n",
    "                    <ul>\n",
    "                        <li>$P(X_{a}) = N(X_{a}|\\mu_{a}, \\Sigma_{aa}^{-1})$\n",
    "                    </ul><br> \n",
    "                <li> <b>2) The conditional distribution</b><br><br>\n",
    "                    <ul>\n",
    "                        <li>$P(X_{a}|X_{b}) = N(X_{a}|\\mu_{a}-\\Sigma_{ab}\\Sigma_{bb}^{-1}(X_{b}-\\mu_{a}), \\; \\Sigma_{aa}-\\Sigma_{ab}\\Sigma_{bb}^{-1}\\Sigma_{ba})$\n",
    "                        <li> As a result, when $X_{a}$ and $X_{b}$ are jointly distributed by a multivariate gaussian distribution, the conditional expectation of $X_{a}$ conditioned on $X_{b}$ is linear in $X_{b}$.\n",
    "                    </ul>        \n",
    "        \n",
    "<br><li> Bayesian inference:\n",
    "    <ul>\n",
    "        <li> $\\sigma$ is known and inferring $\\mu$, the conjugate prior is Gaussian.\n",
    "        <li> $\\mu$ is known and inferring $\\sigma$, the conjugate prior is Inverse-Gamma(Inverse-Wishart for D-dimensional).\n",
    "        <li> Inferring both $\\sigma$ and $\\mu$, the conjugate prior is Normal-Inverse-Gamma(Normal-Inverse-Wishart for D-dimensional).\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e0005",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">    \n",
    "<h3>Student's t distribution</h3><br>\n",
    "<p>$$\\begin{aligned}\n",
    "    p(x|\\mu, a, b) &= \\int_0^\\infty \\mathcal{N}\\left(x |\\mu, \\tau^{-1}\\right)\\text{Gam}(\\tau|a, b) \\ d\\tau \\\\\n",
    "                   &= \\frac{b^a}{\\Gamma(a)}\\left(\\frac{1}{2\\pi}\\right)^{1/2}\\left[b + \\frac{(x - \\mu)^2}{2}\\right]^{-a - 1/2} \\Gamma\\left(a + \\frac{1}{2}\\right)\n",
    "\\end{aligned}$$\n",
    "\n",
    "<p>$$\\text{St}(x\\vert\\mu,\\lambda,v) = \\frac{\\Gamma\\big((v + 1)/2\\big)}{\\Gamma(v/2)}\\left(\\frac{\\lambda}{\\pi v}\\right)^{1/2}\\left[1 + \\frac{\\lambda(x - \\mu)^2}{v}\\right]^{-(v + 1)/2}\n",
    "$$<br>\n",
    "\n",
    "<p>Where, $v = 2a$ is the degrees of freedom of the distribution, $\\lambda = a/b$ is the precision of the distribution<br><br>\n",
    "    \n",
    "<li> Can be defined as the marginal distribution of the unkown $\\mu$ when the dependence on the unkown $\\Sigma$ is marginalized out.\n",
    "<li> Can be interpreted as <b>infinite mixture of Gaussian</b>  \n",
    "<li> Its maximum likelihood solution can be found by expectation maximization algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4541c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">   \n",
    "<h3>Periodic variable</h3><br>\n",
    "<li> Used to model some continuous r.v that Gaussian can't be used(e.g wind direction at some point).\n",
    "<li> To evaluate the mean of $D=\\{\\theta_{1},...,\\theta_{N}\\}$, $\\theta$ id in radian\n",
    "\n",
    "<p>$$\\bar \\theta = \\tan^{-1}\\left(\\frac{\\sum_n \\sin(\\theta_n)}{\\sum_n \\sin(\\theta_n)}\\right)\\\\\n",
    "\\bar X = \\frac{1}{N}\\sum^NX_{n}$$\n",
    "    \n",
    "<li> The periodic generalization of Gaussian is von Mises:<br>\n",
    "\n",
    "<p>$$p(\\theta|\\theta_0, m) = \\frac{1}{2\\pi I_0(m)}\\exp(m\\cos(\\theta - \\theta_0))$$\n",
    "\n",
    "Where $\\theta_0$ is the mean, $m$ is the concentration parameter, $I_0(m)$ is the norm-coefficient which is the zeroth-order Bessel function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a61cc0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
